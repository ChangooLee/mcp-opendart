import json
import os
import time
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
from bs4 import BeautifulSoup

def parse_response_table(soup):
    tables = soup.find_all('table', class_='tb02')
    target_table = None
    for table in tables:
        caption = table.find('caption')
        if caption and 'ì‘ë‹µ ê²°ê³¼' in caption.get_text():
            target_table = table
            break
    if not target_table:
        print("â— 'ì‘ë‹µ ê²°ê³¼' í…Œì´ë¸”ì„ ëª» ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        return None

    tbody = target_table.find('tbody')
    if not tbody:
        print("â— í…Œì´ë¸”ì—ëŠ” tbodyê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

    rows = tbody.find_all('tr')
    if not rows:
        print("â— í…Œì´ë¸”ì—ëŠ” ë°ì´í„° í–‰ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None

    print('rows:', rows)

    result = {}
    parents = {0: result}
    prev_level = 0
    prev_key = None
    for row in rows:
        cols = row.find_all('td')
        if len(cols) < 3:
            continue  # ì»¬ëŸ¼ì´ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ ë¬´ì‹œ

        key_cell = cols[0]
        name = cols[1].get_text(strip=True)
        desc = cols[2].get_text(strip=True)

        span = key_cell.find('span')
        indent = 0
        if span and span.get('class'):
            for cls in span['class']:
                if cls.startswith('mgl'):
                    indent = int(cls[3:])
                    break

        key = key_cell.get_text(strip=True)
        if not key:
            continue

        level = indent // 20
        if key == 'list':
            parents[level][key] = {}
            parents[level + 1] = parents[level][key]
        else:
            # ìƒˆë¡œìš´ levelì´ ë“±ì¥í•˜ë©´ parentsì— ì¶”ê°€
            if level not in parents:
                # prev_keyê°€ Noneì´ë©´ rootë¡œ ì—°ê²°
                if prev_key is not None:
                    parents[level] = parents[prev_level][prev_key]
                else:
                    parents[level] = result

            parents[level][key] = {'name': name, 'description': desc}
            prev_level = level
            prev_key = key

        print('parents:', parents)
        print('ì ‘ê·¼í•˜ë ¤ëŠ” í‚¤:', level)
        # KeyError ë°©ì§€ìš© ì²´í¬ (ë””ë²„ê¹…ìš©)
        if level in parents:
            pass
        else:
            print(f'ê²½ê³ : parentsì— {level} í‚¤ ì—†ìŒ')

    return result


def save_structure_from_urls(json_path):
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    JSON_PATH = os.path.join(BASE_DIR, json_path)

    with open(JSON_PATH, 'r', encoding='utf-8') as f:
        url_dict = json.load(f)

    result = {}

    options = Options()
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-gpu')
    options.add_argument('--window-size=1920,1080')
    options.add_argument('user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')

    driver = webdriver.Chrome(options=options)

    for url in url_dict.keys():
        print(f"[URL] {url}")
        try:
            driver.get(url)

            try:
                WebDriverWait(driver, 20).until(  # ğŸ”¥ ëŒ€ê¸° ì‹œê°„ 20ì´ˆë¡œ ëŠ˜ë¦¼
                    EC.presence_of_element_located((By.CLASS_NAME, 'tb02'))
                )
            except TimeoutException:
                print(f"TimeoutException: í…Œì´ë¸” ë¡œë”© ì‹¤íŒ¨ â” HTML ì €ì¥")
                with open('debug_page.html', 'w', encoding='utf-8') as f:
                    f.write(driver.page_source)
                raise Exception("í…Œì´ë¸”ì´ ë¡œë”©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

            soup = BeautifulSoup(driver.page_source, 'html.parser')
            structure = parse_response_table(soup)

            if structure is not None:
                result[url] = structure
                print(json.dumps(structure, ensure_ascii=False, indent=2))
            else:
                print("ì‘ë‹µ ê²°ê³¼ í…Œì´ë¸”ì„ ì°¾ì§€ ëª»í•¨")
                result[url] = {}

        except Exception as e:
            print(f"Error: {type(e).__name__} - {e}")
            result[url] = {}

    driver.quit()

    output_path = os.path.join(BASE_DIR, 'parsed_response_structures.json')
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    print(f"ëª¨ë“  URLì˜ ì‘ë‹µ ê²°ê³¼ êµ¬ì¡°ë¥¼ ì €ì¥ ì™„ë£Œ: {output_path}")

if __name__ == "__main__":
    save_structure_from_urls('opendart_reference_urls.json')
